---
title: "esm206_lab5"
author: "Emily Pelstring"
date: "10/26/2021"
output: 
  html_document: 
    toc: yes
    theme: yeti
    number_sections: yes
    code_folding: hide
---

```{r setup, include= TRUE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# Confidence Intervals 

In this section, we'll learn to use the 't.test()' function as a way to return the confidence interval using the t-distribution.

## Example 1

Create a mock sample of observation values and find the confidence interval. Then we'll learn how to report that. 

```{r}
pika_mass <- c(82, 94, 110, 70, 86, 99, 102)

pika_mean <- mean(pika_mass)

pika_sd <- sd(pika_mass)

pika_ci <- t.test(pika_mass)

pika_ci

```

### Risky & tedious way: 

This is one way to report your results... 

Mean pika mass at Paiute Pass is 91.9 g $\pm$ 13.5 g (mean $\pm$ 1 standard deviation, n = 7) with a 95% confidence interval of [79.4, 104.4] g. 

### A high initial investment, but safer & better way 

In-line code referencing to stored objects! 

Use a single backtick on either side of a lowercase r to create an in-line bit of code. The round has been added to round the value of pika mean to 1 decimal place. using [] pulls what part of a vector out to report it instead of reporting the whole vector. 

Mean pika mass at Paiute Pass is `r round(pika_mean, 1)` g $\pm$ `r round(pika_sd, 1)` g (mean $\pm$ 1 standard deviation, n = `r length(pika_mass)`) with a 95% confidence interval of [`r pika_ci$conf.int[1]`, `r pika_ci$conf.int[2]`] g.

# Two-sample t-test 

Use a two-sample t-test to test the null hypothessis that samples were drawn from populations with the same mean (difference in means = 0)

- H0: Means difference = 0 
- HA: Means difference is NOT = 0 

This is a two-sided t-test because no directionality is implied. 

## Example 1 

```{r}
oak_trees <- c(29, 19, 22, 30, 35, 16, 20, 7)

pine_trees <- c(48, 32, 41, 40, 56, 70, 30, 19, 20)
```

Is there a significant difference in mean heights for oak and pine trees? 

```{r}
trees_t <- t.test(oak_trees, pine_trees) 
```

The p-value of `r trees_t$p.value` means that there is a `r (trees_t$p.value) * 100`% chance of finding sample means *at least as different as those I found* by random chance if they were drawn from populations with the same mean height. 

## Example 2 

Using the 'mpg' data set to compare city gas mileage for SUVs and compact cars. 

```{r}
# Create a subset called compact_suv that only contains observations where the class is suv OR compact 

compact_suv <- mpg %>%
  filter(class %in% c("suv", "compact"))
```

```{r}
ggplot(data = compact_suv, aes(x = cty)) +
  geom_histogram(bins = 12) + #the default bins is 30 
  facet_wrap(~ class) # separates into two histograms, once for compact cars and one for SUVs

ggplot(data = compact_suv, aes(sample = cty)) + 
  geom_qq() + ## qq plot should only be used in conjunction with other plots and should not be taken as a complete discount of the validity of your linear data 
  facet_wrap(~ class)
```

```{r}
car_stats <- compact_suv %>%
  group_by(class) %>%
  summarize(mean_city = mean(cty),
            sd_city = sd(cty),
            sample_size = n())

car_stats
```

```{r}
compact_sample <- compact_suv %>%
  filter(class == "compact") %>%
  pull(cty)

suv_sample <- compact_suv %>%
  filter(class == "suv") %>%
  pull(cty)

cars_t <- t.test(compact_sample, suv_sample)
```

stats speak: reject the null hypothesis of equal mean city gas mileages. 

Mean gas mileage for compact cars and SUVs differs significantly (t(`r cars_t$parameter`) = `r cars_t$statistic`, p < 0.001, $\alpha$ = 0.05).
